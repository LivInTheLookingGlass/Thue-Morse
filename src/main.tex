\documentclass[conference]{IEEEtran}
\input{macros}
\begin{document}

\title{Extending The \TMS}

\author{\IEEEauthorblockN{Olivia Appleton-Crocker}
\IEEEauthorblockA{\textit{TMW Center for Early Learning + Public Health}\\
\textit{University of Chicago}\\
Chicago, Illinois, United States\\
ORCID: 0009-0004-2296-7033}
\and
\IEEEauthorblockN{Dan Rowe}
\IEEEauthorblockA{\textit{Department of Math and Computer Science}\\
Northern Michigan University\\
Marquette, Michigan, United States\\
Email: darowe@nmu.edu}
}

\maketitle

\begin{abstract}
In this paper, we discuss various ways to extend the \TMS \cite{OEIS-TMS} when used as a fair-share sequence. Included are N definitions of the original sequence, M extensions to n players, and proofs of equality for all definitions. In the appendix are several complexity analyses for both space and time of each definition.
\end{abstract}

\begin{IEEEkeywords}
TBA
\end{IEEEkeywords}

\section{Introduction}

\note{Make sure to add that while this paper does not deal with negative or fractional bases, many of the definitions are trivially extendable to that domain, and at least one of them already has been in another paper.}

\section{The Original Sequence}

\subsection{Definition 1 - Parity of Hamming Weight}

\note{This definition appears in \cite{Spiegelhofer_2020, Allouche-Shallit_1999, OEIS-TMS}}

The Hamming Weight, as typically defined, is the digit sum of a binary number. In other words, it is a count of the high bits in a given number. A common way to generate the \TMS is to take the parity of the Hamming Weight for each natural number. We can use that as follows:

\begin{equation}
    \begin{aligned}
        p(0) &= 0 \\
        p(n) &= n + p\left(\floor{\dfrac{n}{2}}\right) \pmod{2}
    \end{aligned}
\end{equation}

Under this definition, you can construct the \TMS using the following, starting at $0$:

\begin{equation}
    \label{eq:p2d01}
    T_{2,1}(n) = p(n)
\end{equation}

The subscript indicates that we are using $2$ players (writing in base $2$) and that we are using the first definition laid out in this paper. Note that when we extend to n players, the $T$ function will get a second parameter for the number of players, so it will look like $T_{n,d}(x, s)$, where $s$ is the size of the player pool, and therefore the base we use to define the sequence.

\subsection{Definition 2 - Invert and Extend}

\note{Appears in \cite{OEIS-TMS}}

This definition is more natural to think about as extending a tuple that contains the sequence. We will give a recurrence relation below, but to build an intuition we will work in this framework first.

Let $t(n)$ be the first $2^n$ elements of the \TMS. Given this, we can define:

\begin{equation}
    \text{inv}(\mathbf{x}) = \begin{cases}
        0, & \text{if } x_i = 1 \\
        1, & \text{if } x_i = 0
    \end{cases} \quad \text{for } \mathbf{x} = \tuple{x_0, x_1, \ldots, x_{n-1}}
\end{equation}

\begin{equation}
    \begin{aligned}
t(0) &= \tuple{0} \\
t(n) &= t(n - 1) \concat \text{inv}(t(n - 1))
    \end{aligned}
\end{equation}

Given the above, we can define a recurrence relation that will give us individual elements. It will be less efficient to compute, but will allow proofs of equivalence to be easier.

\begin{equation}
    \label{eq:p2d02}
    \begin{aligned}
T_{2,2}(0) &= 0 \\
T_{2,2}(n) &= T_{2,2}\left(n - 2^{\floor{\log_2(n)}}\right) \pm 1 \pmod{2}
    \end{aligned}
\end{equation}

\subsection{Definition 3 - Substitute and Flatten}

\note{This definition appears in \cite{Spiegelhofer_2020, Kolář-Nori_1991, OEIS-TMS}}

\begin{equation}
    \label{eq:p2d03}
    \begin{aligned}
      s(n) &= \begin{cases}
          \tuple{0, 1}, & \text{if } n = 0 \\
          \tuple{1, 0}, & \text{if } n = 1
      \end{cases} \\
      t(0) &= \tuple{0} \\
      t(n) &= \bigparallel_{i=0}^{2^{n-1}-1} s(t(n-1)_i)  \\
T_{2,3}(n) &= t(\ceil{\log_2(n + 1)})_n
    \end{aligned}
\end{equation}

So for example, calculating $T_{2,3}(3)$ would look like:

\begin{equation*}
    \begin{aligned}
      t(0) &= \tuple{0} \\
      t(1) &= \bigparallel_{i=0}^{0} s(t(0)_i) = \tuple{0, 1} \\
      t(2) &= \bigparallel_{i=0}^{1} s(t(1)_i) = \tuple{0, 1, 1, 0} \\
T_{2,3}(3) &= t(\ceil{\log_2(3 + 1)})_3 \\
           &= t(2)_3 \\
           &= \tuple{0, 1, 1, 0}_3 \\
           &= 0
    \end{aligned}
\end{equation*}

\subsection{Definition 4 - Recursive Rotation}

Another way to phrase the above definition is as recursive rotation. If we decompose $s$, we can instead represent it as:

\begin{equation}
    \label{eq:p2d04}
    \begin{aligned}
r(\mathbf{x}, i) &= \begin{aligned}[c]
                   &\tuple{x_{0 + i \mod{|\mathbf{x}|}}, x_{1 + i \mod{|\mathbf{x}|}}, \ldots} \\
                   &\text{for } \mathbf{x} = \tuple{x_0, x_1, \ldots, x_{n-1}}
        \end{aligned} \\
            t(0) &= \tuple{0} \\
            t(1) &= \tuple{0, 1} \\
            t(n) &= \bigparallel_{i=0}^1 r\left(t(n-1), i \cdot 2^{n-2}\right) \\
      T_{2,4}(n) &= t(\ceil{\log_2(n + 1)})_n
    \end{aligned}
\end{equation}

\subsection{Definition 5 - Recursion}

\note{This definition appears in \cite{Kolář-Nori_1991, OEIS-TMS}}

\begin{equation}
    \label{eq:p2d05}
    \begin{aligned}
   T_{2,5}(0) &= 0 \\
  T_{2,5}(2n) &= T_{2,5}(n) \\
T_{2,5}(2n+1) &= 1 - T_{2,5}(n) \pmod{2}
    \end{aligned}
\end{equation}

\subsection{Definition 6 - Highest Bit Difference}

\note{This definition appears in \cite{Arndt_2010}}

\note{The text below is from Wiki and needs to be entirely rewritten. I was able to derive the formula on my own from translating their code. This method leads to a fast method for computing the Thue–Morse sequence: start with t0 = 0, and then, for each n, find the highest-order bit in the binary representation of n that is different from the same bit in the representation of n - 1. If this bit is at an even index, tn differs from tn - 1, and otherwise it is the same as tn - 1.}

\begin{equation}
    \label{eq:p2d06}
    \begin{aligned}
T_{2,6}(0) &= 0 \\
T_{2,6}(n) &= \begin{aligned}[c]
    &\floor{\log_2(n \oplus (n - 1))} \\
    &+ T_{2,6}(n - 1) \pm 1
\end{aligned} \pmod{2}
    \end{aligned}
\end{equation}

\subsection{Definition 7 - Floor-Ceiling Difference}

\note{Appears in \cite{OEIS-TMS}}

\begin{equation}
    \label{eq:p2d07}
    \begin{aligned}
      b(n) &= \begin{cases}
          &n \quad \text{if } n \le 1 \\
          &b\left(\ceil{\dfrac{n}{2}}\right) - b\left(\floor{\dfrac{n}{2}}\right) \quad \text{otherwise}
\end{cases} \\
T_{2,7}(n) &= \dfrac{1 - b(2n)}{2} \pmod{2}
    \end{aligned}
\end{equation}

\note{This seems very similar to the highest bit difference definition, and I think it may be what that was derived from}

\subsection{Definition 8 - Odious Number Derivation}

\note{Definition appears in \cite{OEIS-TMS}}

Another way to generate the \TMS is to take the sequence of Odious Numbers \cite{OEIS-Odious} mod $2$. Odious numbers are those with an odd number of $1$s in their binary representation. Note that the player numbers in this derivation are swapped, so when generating this for testing and extension, we add 1 to the result. Some simple generating code \cite{repo} for this is as follows:

\begin{lstlisting}[style=pythonstyle]
from itertools import count

def seq_p2_d08():
    for i in count():
        if i.bit_count() % 2:
            yield (i + 1) % 2
\end{lstlisting}

\begin{equation}
\label{eq:p2d08}
T_{2,8}(n) = \text{Odious}(n) + 1 \pmod{2}
\end{equation}

\note{Aren't Odious Numbers exactly the numbers where the parity of the hamming weight is 1? So doesn't that mean that the Thue-Morse Sequence selects which numbers are Odious? From cursory testing, it seems to. There's something to be had there.}

\note{A possible way to extend this would be to reinterpret this as where the digit sum is not n-even}

\note{A related definition on OEIS \cite{OEIS-TMS} is
\begin{equation*}
\begin{aligned}
    &T(n) + \text{Odious}(n - 1) + 1 = 2n \text{ for } n \ge 1 \\
    &T(n) = 2n - \text{Odious}(n - 1) - 1
\end{aligned}
\end{equation*}
}

\subsection{Definition 9 - Evil Numbers Derivation 1}

\note{Appears in \cite{OEIS-TMS}}

The Evil Numbers \cite{OEIS-Evil} are those who have an even number of $1$s in their binary representation. Note that this is the opposite of the Odious Numbers referenced above.

\begin{equation}
\label{eq:p2d09}
T_{2,9}(n) = \text{Evil}(n) - 2n \pmod{2}
\end{equation}

\subsection{Definition 10 - Evil Numbers Derivation 2}

\note{Appears in \cite{OEIS-TMS-inv}}

A second, more-efficient derivation from the Evil Numbers is as follows, where $ce()$ is the count of Evil Numbers less than $n$ \cite{OEIS-A159481}, and $p()$ is the function defined in Equation \ref{eq:p2d01}.

\begin{equation}
    \label{eq:p2d10}
    \begin{aligned}
     ce(n) &= \floor{\dfrac{n + 1}{2}} + p(n + 1) \cdot (n + 1 \mod{2}) \\
T_{2,10}(n) &= 1 - ce(n + 1) + ce(n)
    \end{aligned}
\end{equation}

\subsection{Definition 11 - Odious \& Evil Numbers Derivation}

\note{Appears in \cite{OEIS-TMS-inv}}

A second, more-efficient derivation from the Evil Numbers is as follows, where $ce()$ is the count of Evil Numbers less than $n$ \cite{OEIS-A159481}, and $p()$ is the function defined in Equation \ref{eq:p2d01}.

\begin{equation}
    \label{eq:p2d11}
    \begin{aligned}
     oe(n) &= \begin{cases}
         &\text{Odious}\left(\floor{\dfrac{n}{2}}\right) \quad \text{if } n \mod{2} = 0 \\
         &\text{Evil}\left(\floor{\dfrac{n}{2}}\right) \quad\quad\; \text{if } n \mod{2} = 1
     \end{cases} \\
T_{2,11}(n) &= 1 - oe(n) \pmod{2}
    \end{aligned}
\end{equation}

\subsection{Definition 12 - Gould's Sequence Derivation}

\note{Appears in \cite{OEIS-TMS}}

Gould's Sequence \cite{OEIS-Gould} are the number of odd entries in a given row of Pascal's Triangle.

\note{Why mod 3? Everything else is mod 2. This definition is unlikely to be extendable, unless you interpret this as the hamming weight of a given row, and extend the idea of hamming weight to those other bases. If so, I predict that the final mod is mod $(n + 1)$}

\begin{equation}
    \label{eq:p2d12}
    \begin{aligned}
T_{2,12}(n) &= \text{Gould}(n) - 1 \mod{3} \\
            &= \left(\sum_{k=0}^n \left(\binom{n}{k} \mod{2} \right)\right) - 1 \mod{3}
    \end{aligned}
\end{equation}

\subsection{Definition 13 - Derivation from Blue Code}

\note{Appears in \cite{OEIS-TMS}}

In the OEIS, this sequence \cite{OEIS-A193231} is defined as the "binary coding of a polynomial over GF(2), substitute x+1 for x". There are a number of ways to generate it. One of the more computationally-accessible ones is:

\begin{equation}
    \label{eq:p2d13}
    \begin{aligned}
\text{A001317}(n) &= \sum_{k=0}^n \left(\binom{n}{k} \mod{2} \right) \cdot 2^k \\
\text{A193231}(n) &= \bigoplus_{i=0}^{\ceil{\log_2(n)}} \hspace{-5pt} \text{A001317}\left(i \cdot \floor{\dfrac{n \mod{2}}{2^i}}\right) \\
      T_{2,13}(n) &= \text{A193231}(n) \pmod{2}
    \end{aligned}
\end{equation}

Translated into words, this function computes the value of Sierpiński's triangle for the index of each high bit, then takes the bitwise exclusive or of all such resulting values. Note that since $\text{A001317}(n) = 0$, each low bit can be simplified out when calculating.

\note{It seems to me that this might be extendable by using GF(n) instead of GF(2), though I don't know of a way to efficient compute or prove such a result}

\subsection{Summary}

\section{Proving Equivalence Between Standard Definitions}

\subsection{Correlating Definition 1 and Definition 5}

Note that in Equation \ref{eq:p2d05} where we define $T_{2,5}$, we are working in mod 2, where $+1$ and $-1$ are logically equivalent. We can therefore simplify its definition to be:

\begin{equation}
    \label{eq:p2d05s}
    \begin{aligned}
T_{2,5}(0) &= 0 \\
T_{2,5}(n) &= n + T_{2,5}\left(\floor{\dfrac{n}{2}}\right) \pmod{2}
    \end{aligned}
\end{equation}

This is identical to Equation \ref{eq:p2d01}, where we define $T_{2,1}$.

\section{The Extensions}

\subsection{Definition 1 - Modular Digit Sums}

\note{Definition appears in \cite{Astudillo_2003, Dekking_2023}}

To extend definition 1 from $2$ to $n$ players, we must first map our concept of parity to base n. We can do this by taking the parity equation defined above and replacing the $2$s with $n$, for $n \in \Integers_{\ge 2}$.

\begin{equation}
    \begin{aligned}
p_n(0) &= 0 \\
p_n(x) &= x + p_n\left(\floor{\dfrac{x}{n}}\right) \pmod{n}
    \end{aligned}
\end{equation}

Under this definition, you can construct the \TMS using the following, starting at 0:

\begin{equation}
    \label{eq:pnd01}
    T_{n,1}(x, s) = p_s(x)
\end{equation}

\subsubsection{Proof of Equivalence with Original Definition 1}

It is clear from visual inspection that $p_2$ is identical to our original definition of $p$.

\begin{equation}
    \begin{aligned}
                                                           p_2(x) &= p(x) \\
                         x + p_2\left(\floor{\dfrac{x}{2}}\right) &= x + p\left(\floor{\dfrac{x}{2}}\right) \\
x + \floor{\dfrac{x}{2}} + p_2\left(\floor{\dfrac{x}{2^2}}\right) &= x + \floor{\dfrac{x}{2}} + p\left(\floor{\dfrac{x}{2^2}}\right) \\
       x + \floor{\dfrac{x}{2}} + \floor{\dfrac{x}{2^2}} + \ldots &= x + \floor{\dfrac{x}{2}} + \floor{\dfrac{x}{2^2}} + \ldots
    \end{aligned}
\end{equation}

\subsection{Definition 2 - Increment and Extend}

In the original version of this definition, we inverted the elements. In base $2$, this is the same thing as adding $1$ (mod $2$). Given that, let $t(x, n)$ be the first $n^x$ elements of the \ETMS, for $n \in \Integers_{\ge 2}$.

\begin{equation}
    \text{inc}(\mathbf{x}, n) = \begin{aligned}[c]
            &x_i + 1 \pmod{n} \\
            &\text{for } \mathbf{x} = (x_0, x_1, \ldots, x_{n-1})
    \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
t(0, n) &= \tuple{0} \\
t(1, n) &= \tuple{0, 1, \ldots, n - 1} \\
t(x, n) &= t(x - 1, n) \cdot \text{inc}(t(x - 1, n), n)
    \end{aligned}
\end{equation}

Given the above, we can define a recurrence relation that will give us individual elements. It will be less efficient to compute, but will allow proofs of equivalence to be easier.

\begin{equation}
    \label{eq:pnd02}
    \begin{aligned}
T_{n,2}(0, s) &= 0 \\
T_{n,2}(x, s) &= T_{n,2}\left(x - s^{\floor{\log_s(x)}}, s\right) + 1 \pmod{s}
    \end{aligned}
\end{equation}

\subsubsection{Proof of Equivalence with Original Definition 2}

\subsection{Definition 3 - Substitute and Flatten}

\note{There's a bit of a leap here, since we have to explain why the rotation is equivalent to the binary choice presented in the original. There also might be a better syntax to define the rotation, perhaps using the format used in inv and inc.}

\begin{equation}
    \label{eq:pnd03}
    \begin{aligned}
            b(s) &= \tuple{0, 1, \cdots, s - 2, s - 1} \\
r(\mathbf{x}, i) &= \begin{aligned}[c]
                   &\tuple{x_{0 + i \mod{|\mathbf{x}|}}, x_{1 + i \mod{|\mathbf{x}|}}, \ldots} \\
                   &\text{for } \mathbf{x} = \tuple{x_0, x_1, \ldots, x_{n-1}}
        \end{aligned} \\
         s(x, s) &= r(b(s), x) \\
            t(0) &= \tuple{0} \\
         t(x, s) &= \bigparallel_{i=0}^{2^{x-1}-1} s(t(x-1)_i, s)  \\
   T_{n,3}(x, s) &= t(\ceil{\log_s(x + 1)}, s)_x
    \end{aligned}
\end{equation}

\subsubsection{Proof of Equivalence with Original Definition 3}

\subsection{Definition 4 - Recursive Rotation}

\begin{equation}
    \label{eq:pnd04}
    \begin{aligned}
r(\mathbf{x}, i) &= \begin{aligned}[c]
                   &\tuple{x_{0 + i \mod{|\mathbf{x}|}}, x_{1 + i \mod{|\mathbf{x}|}}, \ldots} \\
                   &\text{for } \mathbf{x} = \tuple{x_0, x_1, \ldots, x_{n-1}}
        \end{aligned} \\
         t(0, s) &= \tuple{0} \\
         t(1, s) &= \tuple{0, 1, \ldots, s - 1} \\
         t(x, s) &= \bigparallel_{i=0}^{s-1} r\left(t(x-1, s), i \cdot s^{x-2}\right) \\
   T_{n,4}(x, s) &= t(\ceil{\log_s(x + 1)}, s)_x
    \end{aligned}
\end{equation}

\subsubsection{Proof of Equivalence with Original Definition 4}

\subsection{Definition 5 - Recursion}

\note{Need to reference eq \ref{eq:p2d05s} in definition}

\subsubsection{Proof of Equivalence with Original Definition 5}

\subsection{Definition 6 - Highest Digit Difference}

\begin{equation}
    \begin{aligned}
\text{XOR}_{n}(a, b) &= \hspace{-13pt} \sum_{i=0}^{\ceil{\log_{n}(\max(a,b) + 1)}} \hspace{-15pt} n^i \left(\floor{\dfrac{a}{n^i}} - \floor{\dfrac{b}{n^i}} \mod{n}\right) \\
       T_{n,6}(0, s) &= 0 \\
       T_{n,6}(x, s) &= \begin{aligned}[c]
           &\floor{\log_s(\text{XOR}_{s}(x, x - 1))} \\
           &+ T_{n,6}(x - 1, s) + 1
       \end{aligned} \pmod{s}
    \end{aligned}
\end{equation}

\note{This is tested up to $2^{22} \cdot n, n \in [2, 32]$}

\note{Substitute n for 2, then simplify, plus a bit}

\subsubsection{Proof of Equivalence with Original Definition 6}

\subsection{Summary}

\section{Proving Equivalence Between Extended Definitions}

\subsection{Summary}

\section{Proving Persistence of Original Properties}

\section{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without 
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
acknowledgments in the unnumbered footnote on the first page.

\section{Appendix}

\subsection{Complexity of Original Definition 1}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 2}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 3}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 4}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 5}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 6}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 7}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 8}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 9}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 10}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 11}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 12}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Original Definition 13}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 1}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 2}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 3}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 4}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 5}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\subsection{Complexity of Extension Definition 6}

\subsubsection{Time Complexity}

\subsubsection{Space Complexity}

\bibliographystyle{unsrt}
\bibliography{references}     % without the .bib extension

\onecolumn
\clearpage
\lstset{basicstyle=\ttfamily, breaklines=true}
\lstinputlisting{notes/definitions_to_add.txt}

\end{document}
